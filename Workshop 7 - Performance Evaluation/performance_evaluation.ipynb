{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a15dc821-7108-46a9-bad5-4f6f59121f8d",
   "metadata": {},
   "source": [
    "# Workshop 7 - Performance Evaluation\n",
    "\n",
    "In this workshop we're going to take two models, and compare and present them as if we're pitching to stakeholders.\n",
    "\n",
    "In this case we'll compare a gradient boosting model and a random forest model, using the full procedure including nested CV. This time around we'll be using the Presence/Absence gene features in the interest of time as the models train much faster\n",
    "\n",
    "Lets run through the steps together (there are some questions and some blanks to fill in as we run through)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7140deb-bd7d-48db-9a5a-367700da47a3",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d595ae-d425-4900-8b62-7136b25e777e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import sklearn\n",
    "from sklearn import linear_model\n",
    "from sklearn import tree\n",
    "from sklearn import ensemble\n",
    "from tensorflow import keras\n",
    "import bayes_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e327e0dd-fa16-4a1b-aea9-a2e7b2e17d01",
   "metadata": {},
   "source": [
    "## 1. Load Data\n",
    "\n",
    "\n",
    "For this workshop please download the latest:\n",
    "- `train_test_data` folder and put within `data/`\n",
    "\n",
    "Key for data:\n",
    "- train_pa_genes = presence absence binary features for training data\n",
    "- test_pa_genes = presence absence binary features for test data\n",
    "- y_train = array of S/R target values\n",
    "- y_train_ids = array of genome_ids in order of y_train\n",
    "- y_test_ids = array of genome_ids in order of y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fd3c81-1867-4819-b907-5f5816a41379",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 130\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"\n",
    "    Load the data needed for Workshop 5\n",
    "    \"\"\"\n",
    "    # Load PA data\n",
    "    train_pa_genes = pd.read_csv('../data/train_test_data/train_pa_genes.csv').set_index('genome_id')\n",
    "    test_pa_genes = pd.read_csv('../data/train_test_data/test_pa_genes.csv').set_index('genome_id')\n",
    "    \n",
    "    # Load target data & IDs\n",
    "    y_train = np.load('../data/train_test_data/y_train.npy', allow_pickle=True)\n",
    "    y_train_ids = np.load('../data/train_test_data/train_ids.npy', allow_pickle=True).astype(str)\n",
    "    y_test_ids = np.load('../data/train_test_data/test_ids.npy', allow_pickle=True).astype(str)\n",
    "    \n",
    "    return train_pa_genes, test_pa_genes, y_train, y_train_ids, y_test_ids\n",
    "\n",
    "X_train_pa, X_test_pa, y_train, y_train_ids, y_test_ids = load_data()\n",
    "X_train, X_test = np.array(X_train_pa), np.array(X_test_pa)\n",
    "y_train = y_train.reshape(-1) # convert to vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b354afc5-3d28-4f03-9c52-8dea927efed0",
   "metadata": {},
   "source": [
    "## 2. Use Nested CV to Optimize & Estimate Model Performance\n",
    "\n",
    "Before we review and analyze we need to train a few models used nested CV\n",
    "\n",
    "Nested CV will allow us to both hyperparameter tune on the inner fold & get an unbiased estimate of performance on the outer fold\n",
    "\n",
    "**Notes:**\n",
    "\n",
    "We're doing 5 outer CV folds for model assessment, training 2 models and for each of those doing 10 random parameter searches on the inner 5 fold CV.\n",
    "\n",
    "All in all this means we're training: 5x10x2x5 = 500 individual models!\n",
    "\n",
    "No wonder we don't want to do this for training neural networks. As mentioned this nested CV approach is the full package for giving both a fair assessment of model fit and finding the best parameters, it will not always be viable/possible depending on time/cost constraints.\n",
    "\n",
    "In this case we're using the presence/absence features where the data size is small and the models train in fractions of a second. For the kmer models this process could take hours!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65254eb-5905-4ef6-bf3a-135aeb11bce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First build a manual K-fold loop using K=5\n",
    "K = 5\n",
    "kfold = sklearn.model_selection.KFold(\n",
    "    n_splits = K,\n",
    "    shuffle = True, # Want to shuffle as seen in slides\n",
    "    random_state = seed, # To ensure reproducible results\n",
    ")\n",
    "\n",
    "rf_fold_perf = {}\n",
    "gb_fold_perf = {}\n",
    "\n",
    "# Loop through each of our 5 outer folds once at a time\n",
    "for i, (train_index, val_index) in enumerate(kfold.split(X_train)):\n",
    "\n",
    "    print(f\"Starting Outer fold {i}\")\n",
    "    X_train_outer, X_val_outer, y_train_outer, y_val_outer  = (\n",
    "        X_train[train_index], X_train[val_index], y_train[train_index], y_train[val_index]\n",
    "    )\n",
    "\n",
    "    # RANDOM FOREST MODEL FIT AND EVALUATE\n",
    "    print(\"Optimizing RFC\")\n",
    "    rfc_random_cv = sklearn.model_selection.RandomizedSearchCV(\n",
    "        estimator = ensemble.RandomForestClassifier(random_state = seed),\n",
    "        param_distributions = {\n",
    "            \"n_estimators\" : stats.randint(low=1, high=20),\n",
    "            \"max_depth\": stats.randint(low=1, high=10),\n",
    "        },\n",
    "        n_iter = 10, # Sample 4 times from distribution\n",
    "        cv = 5, # Use 2 fold CV (for speed, in reality we'd want to set to some higher number 5/10 etc.)\n",
    "        scoring = sklearn.metrics.make_scorer(sklearn.metrics.balanced_accuracy_score) # Use balanced accuracy to score\n",
    "    )\n",
    "    \n",
    "    # Fit the model\n",
    "    rfc_random_cv.fit(X_train_outer, y_train_outer)  # Here we're using just the train_outer from our manual K-fold split\n",
    "\n",
    "    # Assess the best model using the outer validation data\n",
    "    y_pred_outer_rfc = rfc_random_cv.predict(X_val_outer)\n",
    "    rf_fold_perf[i] = sklearn.metrics.confusion_matrix(y_val_outer, y_pred_outer_rfc, labels=[\"S\",\"R\"])\n",
    "    \n",
    "    # GRADIENT BOOSTING MODEL FIT AND EVALUATE\n",
    "    print(\"Optimizing GBC\")\n",
    "    gbc_random_cv = sklearn.model_selection.RandomizedSearchCV(\n",
    "        estimator = ensemble.AdaBoostClassifier(\n",
    "            estimator = tree.DecisionTreeClassifier(max_depth=1),\n",
    "            algorithm=\"SAMME\",\n",
    "        ),\n",
    "        param_distributions = {\n",
    "            \"n_estimators\" : stats.randint(low=1, high=20),\n",
    "            \"learning_rate\": stats.loguniform(0.001, 1),\n",
    "        },\n",
    "        n_iter = 10, # Sample 4 times from distribution\n",
    "        cv = 5, # Use 2 fold CV (for speed, in reality we'd want to set to some higher number 5/10 etc.)\n",
    "        scoring = sklearn.metrics.make_scorer(sklearn.metrics.balanced_accuracy_score) # Use balanced accuracy to score\n",
    "    )\n",
    "\n",
    "    # Fit the model\n",
    "    gbc_random_cv.fit(X_train_outer, y_train_outer)  # Here we're using just the train_outer from our manual K-fold split\n",
    "\n",
    "    # Assess the best model using the outer validation data\n",
    "    y_pred_outer_gbc = gbc_random_cv.predict(X_val_outer)\n",
    "    gb_fold_perf[i] = sklearn.metrics.confusion_matrix(y_val_outer, y_pred_outer_gbc, labels=[\"S\",\"R\"])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b248833c-9a70-40c1-a29d-e39ca6851fb3",
   "metadata": {},
   "source": [
    "## 3. Review the Model outputs\n",
    "\n",
    "At this point we've saved out the confusion matrices for both models on each of our outer folds\n",
    "- The inner fold information is hidden from us at this point (we didn't store it)\n",
    "- This isn't important though, we just need to know that the best model we could find was chosen\n",
    "- We're using the outer folds for our unbiased performance assessment\n",
    "\n",
    "What do we want to present?\n",
    "- Confusion matrices\n",
    "- Sensitivity/Specificity\n",
    "- Balanced accuracy\n",
    "- Mean and Variance across folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838a61d1-11af-4d8c-a7e1-b8dd3a50d92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at what we kept from the random forest model\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2609c0f-3675-41aa-be89-2ee9bc406641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all the data across folds into a single matrix\n",
    "combined_matrix = ---\n",
    "pd.DataFrame(data = combined_matrix, index=[\"S\", \"R\"], columns=[\"S\",\"R\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ffad9f-4912-4cfe-8eb7-9302ce3cff15",
   "metadata": {},
   "source": [
    "#### Calculate Metrics:\n",
    "\n",
    "First we can simplify and find the mean of all our metrics (using the mean of the confusion matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c6aeea-e0b5-4182-8633-ba45bf0b6c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(confusion_matrix):\n",
    "    # Accuracy = correct / total\n",
    "    accuracy = (---) / ---\n",
    "    \n",
    "    # Sensitivity = Fraction of positive class predicted correctly\n",
    "    sensitivity = --- / ---\n",
    "    \n",
    "    # Specificity = Fraction of negative class predicted correctly\n",
    "    specificity = --- / ---\n",
    "    \n",
    "    # Balanced accuracy = average of sensitivity and specificity\n",
    "    balanced_accuracy = np.mean([sensitivity, specificity])\n",
    "\n",
    "    return accuracy, sensitivity, specificity, balanced_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef15c51-28b2-409a-aa72-ab29e7813472",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_rf, sensitivity_rf, specificity_rf, balanced_accuracy_rf = calculate_metrics(combined_matrix)\n",
    "\n",
    "print(f\"Accuracy: {np.round(accuracy_rf, 2)}\")\n",
    "print(f\"Sensitivity: {np.round(sensitivity_rf, 2)}\")\n",
    "print(f\"Specificity: {np.round(specificity_rf, 2)}\")\n",
    "print(f\"Balanced Accuracy: {np.round(balanced_accuracy_rf, 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482ddfa2-b540-4003-919b-e9e2a633b62b",
   "metadata": {},
   "source": [
    "#### Lets check for our other model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613bf731-0135-42f3-a5e2-1d1ab734007e",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_gb, sensitivity_gb, specificity_gb, balanced_accuracy_gb = calculate_metrics(\n",
    "    np.mean(list(gb_fold_perf.values()), axis=0)\n",
    ")\n",
    "\n",
    "print(f\"Accuracy: {np.round(accuracy_gb, 2)}\")\n",
    "print(f\"Sensitivity: {np.round(sensitivity_gb, 2)}\")\n",
    "print(f\"Specificity: {np.round(specificity_gb, 2)}\")\n",
    "print(f\"Balanced Accuracy: {np.round(balanced_accuracy_gb, 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61ad7c3-c9c4-4973-aa5a-ba5b0e3a6ae8",
   "metadata": {},
   "source": [
    "<div class=\"question\" style=\"color: #534646; background-color: #ffdfa3; padding: 1px; border-radius: 5px;\">\n",
    "\n",
    "#### Q. Do we know which model is better?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa04f850-f1f3-46b7-827b-6e4ad22446e4",
   "metadata": {},
   "source": [
    "## 4. Across Fold Variability\n",
    "\n",
    "How much do the individual models vary across folds?\n",
    "\n",
    "Importantly - if we train this model again do we expect to get close to the performance we see above?\n",
    "\n",
    "Instead of combining matrices and calculating metrics, lets calculation the variability across each metric\n",
    "- We can use confidence intervals!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844a2271-359f-43fd-bae2-a606f69a307d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_normal_confidence_intervals(confusion_matrices_list):\n",
    "\n",
    "    acc_list = []\n",
    "    sens_list = []\n",
    "    spec_list = []\n",
    "    ba_list = []\n",
    "    for confusion_matrix in confusion_matrices_list:\n",
    "        # Accuracy = correct / total\n",
    "        acc_list.append((confusion_matrix[0,0] + confusion_matrix[1,1]) / confusion_matrix.sum())\n",
    "        sens_list.append(confusion_matrix[1,1] / confusion_matrix[1,:].sum())\n",
    "        spec_list.append(confusion_matrix[0,0] / confusion_matrix[0,:].sum())\n",
    "        ba_list.append(np.mean([confusion_matrix[1,1] / confusion_matrix[1,:].sum(), \n",
    "                                confusion_matrix[0,0] / confusion_matrix[0,:].sum()]))\n",
    "\n",
    "    loc, std = np.mean(acc_list), np.std(acc_list)\n",
    "    accuracy_ci = stats.norm.interval(0.95, loc=loc, scale=std)\n",
    "\n",
    "    loc, std = np.mean(sens_list), np.std(sens_list)\n",
    "    sensitivity_ci = stats.norm.interval(0.95, loc=loc, scale=std)\n",
    "\n",
    "    loc, std = np.mean(spec_list), np.std(spec_list)\n",
    "    specificity_ci = stats.norm.interval(0.95, loc=loc, scale=std)\n",
    "\n",
    "    loc, std = np.mean(ba_list), np.std(ba_list)\n",
    "    balanced_accuracy_ci = stats.norm.interval(0.95, loc=loc, scale=std)\n",
    "    \n",
    "    return accuracy_ci, sensitivity_ci, specificity_ci, balanced_accuracy_ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71075d93-0cdb-465e-9085-7d1879d34384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Random Forest Model\n",
    "acc_ci_rf, sens_ci_rf, spec_ci_rf, ba_ci_rf = calculate_normal_confidence_intervals(list(rf_fold_perf.values()))\n",
    "\n",
    "# For Gradient Boosted Model\n",
    "acc_ci_gb, sens_ci_gb, spec_ci_gb, ba_ci_gb = calculate_normal_confidence_intervals(list(gb_fold_perf.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d2120f-0ba0-4b3b-bfa1-0d20e9a2c7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ba_ci_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f26e60a-0d7e-48bc-bb2d-a1f29eec254f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ba_ci_gb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5257a99a-1b3e-44df-aa35-b0d36d01f17f",
   "metadata": {},
   "source": [
    "#### If we had more time we could also check how confident we should be in individual statistic based on sample size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610fea6c-69bd-4245-9bc2-7231423c8c18",
   "metadata": {},
   "source": [
    "## 5. Present Results\n",
    "\n",
    "Given our two models - how can we easily summarize and present this information?\n",
    "\n",
    "- Lets make a quick plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f2345b-3536-46dd-a50f-1fe2661e9085",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(12,5))\n",
    "\n",
    "xerr = np.array((balanced_accuracy_rf - ba_ci_rf[0], ba_ci_rf[1] - balanced_accuracy_rf)).reshape(2,1)\n",
    "ax.errorbar(---, fmt='o', label = \"Random Forest\")\n",
    "\n",
    "xerr = np.array((balanced_accuracy_gb - ba_ci_gb[0], ba_ci_gb[1] - balanced_accuracy_gb)).reshape(2,1)\n",
    "ax.errorbar(---, fmt='o', label = \"Adaboost\")\n",
    "ax.set_yticks([])\n",
    "ax.set_title(\"Balanced Accuracy Comparison\")\n",
    "ax.set_ylim(-0.5, 1.5)\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3253c1e8-42ef-4322-a382-77ce699fa670",
   "metadata": {},
   "source": [
    "<div class=\"question\" style=\"color: #534646; background-color: #ffdfa3; padding: 1px; border-radius: 5px;\">\n",
    "\n",
    "#### Q. Now what do we think?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d609963-412b-4df2-af6e-1d894cacde0d",
   "metadata": {},
   "source": [
    "## 6. Train a Final Model\n",
    "\n",
    "Now we have a very strong idea of how we expect out final model to perform, we can now ignore the evaluation portion.\n",
    "\n",
    "Our final assessment will be predictions on the final test dataset (Kaggle competition dataset).\n",
    "\n",
    "So now we want to use a single CV fold to train our final model on all the data.\n",
    "- For the above assessment to be valid we need to use the same modeling procedure\n",
    "- We can think about our \"model\" as the full fitting process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb76eb9-838b-48b6-b455-f9cacba928f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the same CV process to find out final model but across all the training data\n",
    "gbc_final_cv = sklearn.model_selection.RandomizedSearchCV(\n",
    "    estimator = ensemble.AdaBoostClassifier(\n",
    "        estimator = tree.DecisionTreeClassifier(max_depth=1),\n",
    "        algorithm=\"SAMME\",\n",
    "    ),\n",
    "    param_distributions = {\n",
    "        \"n_estimators\" : stats.randint(low=1, high=20),\n",
    "        \"learning_rate\": stats.loguniform(0.001, 1),\n",
    "    },\n",
    "    n_iter = 10, # Sample 10 times from distribution\n",
    "    cv = 5, # Use 5 fold CV \n",
    "    scoring = sklearn.metrics.make_scorer(sklearn.metrics.balanced_accuracy_score) # Use balanced accuracy to score\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "gbc_final_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d184e517-b1aa-47bb-b878-48179624f94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find our optimal parameters and train a single model:\n",
    "final_lr = gbc_final_cv.best_estimator_.get_params()[\"learning_rate\"]\n",
    "final_n_est = gbc_final_cv.best_estimator_.get_params()[\"n_estimators\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c702d096-7efa-470f-b0b1-6c1ab11ae6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_lr, final_n_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cee7f8-8f3e-476e-a828-b966c169a7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit final model\n",
    "final_model = ensemble.AdaBoostClassifier(\n",
    "    estimator = tree.DecisionTreeClassifier(max_depth=1),\n",
    "    algorithm=\"SAMME\",\n",
    "    learning_rate = final_lr, \n",
    "    n_estimators = final_n_est,\n",
    ")\n",
    "final_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f3594f-74a1-4f91-bdce-d037cb7d77f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = final_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c850834f-96b8-4358-a814-ba448a1a3474",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictions = pd.DataFrame(data = {\"genome_id\":y_test_ids, \"y_pred\":y_pred_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b998afce-ad18-492f-8406-c9e2267be232",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25621363-a0ec-430c-a467-9a305bcd2593",
   "metadata": {},
   "source": [
    "### And we're done!\n",
    "\n",
    "- We have our final model which we can use to make predictions\n",
    "- The test submissions can be submitted as our final single assessment of the model\n",
    "- In order to understand how well we expect the model to perform, we have the Nested CV results\n",
    "- The model is clearly highly variable\n",
    "- We might expect to reasonably see anywhere from 68% - 98% balanced accuracy!\n",
    "- Even if this particular model does well we don't expect this to be a great model overall\n",
    "\n",
    "Next steps would be to write this up, check how well the model performs individually on sensitivity and specificity and iterate!\n",
    "- Can we solve our high variability problem?\n",
    "- Is the model unstable\n",
    "- Is our data too variable?\n",
    "- We didn't use sample weighting - maybe the model is struggling on the minority class?\n",
    "- Or maybe we need to stratify our splits to ensure even balance of S to R\n",
    "- Always need to iterate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f172efc-75c5-4677-ac5e-d86e80bbcb93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
